import datetime
import io
import re
from collections import Counter

import altair as alt
import numpy as np
import pandas as pd
import streamlit as st

st.set_page_config(page_title="æˆæ¥­ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆè§£æ", page_icon="ğŸ“Š")
st.title("ğŸ“Š æˆæ¥­ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆè§£æãƒ„ãƒ¼ãƒ«")
st.write(
    """
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆçµæœã‚’è§£æã—ã¾ã™ã€‚
    æœŸå¾…ã•ã‚Œã‚‹CSVã®ã‚«ãƒ©ãƒ ï¼ˆãƒ˜ãƒƒãƒ€ï¼‰ã¯æ¬¡ã®ã¨ãŠã‚Šã§ã™:
    ç•ªå·,å­¦ç”Ÿç•ªå·,ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆå›ç­”,æˆæ¥­ãŒå½¹ç«‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰,æˆæ¥­ãŒé›£ã—ã‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰,å›ç­”æ—¥æ™‚
    """
)

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader(
    "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆUTF-8ã€ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰",
    type=["csv"],
    help="ãƒ˜ãƒƒãƒ€è¡Œ: ç•ªå·,å­¦ç”Ÿç•ªå·,ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆå›ç­”,æˆæ¥­ãŒå½¹ç«‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰,æˆæ¥­ãŒé›£ã—ã‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰,å›ç­”æ—¥æ™‚",
)

# ã‚µãƒ³ãƒ—ãƒ«CSVï¼ˆè¡¨ç¤ºç”¨ï¼‰
sample_csv = """ç•ªå·,å­¦ç”Ÿç•ªå·,ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆå›ç­”,æˆæ¥­ãŒå½¹ç«‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰,æˆæ¥­ãŒé›£ã—ã‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰,å›ç­”æ—¥æ™‚
1,S053,ã“ã®æˆæ¥­ã§å¾®ç©åˆ†ã«å¯¾ã™ã‚‹ç†è§£ãŒæ·±ã¾ã£ãŸã€‚ç‰¹ã«æ¼”ç¿’å•é¡ŒãŒè‰¯ã‹ã£ãŸã€‚,5,3,2025-10-25 10:05:12
2,S012,æ¿æ›¸ãŒå°‘ã—æ—©ãã¦ã¤ã„ã¦ã„ãã®ãŒå¤§å¤‰ã ã£ãŸãŒã€å†…å®¹ã¯ã¨ã¦ã‚‚ãŸã‚ã«ãªã£ãŸã€‚,4,4,2025-10-25 10:11:34
3,S076,åŸºæœ¬ã‹ã‚‰ä¸å¯§ã«æ•™ãˆã¦ãã‚Œã¦åˆ†ã‹ã‚Šã‚„ã™ã‹ã£ãŸã€‚å¿œç”¨å•é¡Œã«ã‚‚ã£ã¨æŒ‘æˆ¦ã—ãŸã„ã€‚,5,2,2025-10-25 10:18:55
4,S009,æ­£ç›´ã€å°‘ã—é€€å±ˆã ã£ãŸã€‚ã‚‚ã†å°‘ã—å®Ÿç”Ÿæ´»ã¨ã®é–¢é€£ã‚’èª¬æ˜ã—ã¦ã»ã—ã‹ã£ãŸã€‚,2,3,2025-10-25 10:25:01
5,S034,å…ˆç”Ÿã®èª¬æ˜ãŒè«–ç†çš„ã§åˆ†ã‹ã‚Šã‚„ã™ã„ã€‚æ•°å­¦ã®æ¥½ã—ã•ãŒå°‘ã—åˆ†ã‹ã£ãŸæ°—ãŒã™ã‚‹ã€‚,5,3,2025-10-25 10:32:40
6,S022,èª²é¡Œã®é‡ãŒå¤šãã¦è² æ‹…ã ã£ãŸãŒã€ãã®åˆ†åŠ›ãŒã¤ã„ãŸã¨æ€ã†ã€‚,4,5,2025-10-25 10:38:09
7,S061,ã‚°ãƒ«ãƒ¼ãƒ—ãƒ¯ãƒ¼ã‚¯ãŒæ¥½ã—ã‹ã£ãŸã€‚ä»–ã®å­¦ç”Ÿã¨è­°è«–ã™ã‚‹ã“ã¨ã§ç†è§£ãŒæ·±ã¾ã£ãŸã€‚,5,3,2025-10-25 10:44:17
8,S002,äºˆç¿’ãŒå¿…é ˆã ã¨æ„Ÿã˜ãŸã€‚ã¤ã„ã¦ã„ããŸã‚ã«ã‹ãªã‚ŠåŠªåŠ›ãŒå¿…è¦ã ã£ãŸã€‚,3,5,2025-10-25 10:50:22
9,S073,æˆæ¥­ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚‚ã¡ã‚‡ã†ã©è‰¯ãã€é‡è¦ãªãƒã‚¤ãƒ³ãƒˆãŒæ˜ç¢ºã ã£ãŸã€‚,4,2,2025-10-25 10:57:38
10,S030,æ•™ç§‘æ›¸é€šã‚Šã®å†…å®¹ã ã£ãŸãŒã€è§£èª¬ãŒä¸å¯§ã§ç†è§£ã—ã‚„ã™ã‹ã£ãŸã€‚,4,3,2025-10-25 11:03:00
"""

def load_csv(file) -> pd.DataFrame:
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ or str
    if isinstance(file, str):
        buf = io.StringIO(file)
        df = pd.read_csv(buf)
    else:
        # streamlit ã® UploadedFile ã¯ãƒã‚¤ãƒŠãƒªãªã®ã§ decode
        try:
            df = pd.read_csv(file)
        except Exception:
            file.seek(0)
            df = pd.read_csv(io.TextIOWrapper(file, encoding="utf-8"))
    return df

def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    # æœŸå¾…ã™ã‚‹ã‚«ãƒ©ãƒ åã®ç°¡æ˜“ãƒãƒƒãƒãƒ³ã‚°ã¨ãƒªãƒãƒ¼ãƒ 
    col_map = {}
    cols = list(df.columns)
    for c in cols:
        c_norm = re.sub(r"\s+", "", c).lower()
        if "ç•ªå·" in c or c_norm == "id" or c_norm == "number":
            col_map[c] = "ç•ªå·"
        elif "å­¦ç”Ÿ" in c or "student" in c_norm:
            col_map[c] = "å­¦ç”Ÿç•ªå·"
        elif "ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆ" in c or "answer" in c_norm or "comment" in c_norm:
            col_map[c] = "ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆå›ç­”"
        elif "å½¹ç«‹" in c or "help" in c_norm:
            col_map[c] = "æˆæ¥­ãŒå½¹ç«‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰"
        elif "é›£ã—" in c or "difficult" in c_norm:
            col_map[c] = "æˆæ¥­ãŒé›£ã—ã‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰"
        elif "æ—¥æ™‚" in c or "date" in c_norm:
            col_map[c] = "å›ç­”æ—¥æ™‚"
    return df.rename(columns=col_map)

def safe_to_numeric(s):
    try:
        return pd.to_numeric(s)
    except Exception:
        return pd.Series(dtype="float64")

def extract_top_words(series: pd.Series, top_n=10):
    # ç°¡æ˜“ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ï¼šæ—¥æœ¬èªã®å˜èªåˆ†å‰²ã¯ã—ã¦ã„ãªã„ã®ã§ã€ã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠãƒ»æ¼¢å­—ã®é€£ç¶šã‚’æŠ½å‡º
    texts = series.dropna().astype(str).tolist()
    tokens = []
    for t in texts:
        # è‹±æ•°å­—ã¯åˆ†ã‘ã‚‹ã€è¨˜å·é™¤å»
        t_clean = re.sub(r"[^\w\u3000-\u303F\u4E00-\u9FFF\u3040-\u309F\u30A0-\u30FF]", " ", t)
        # çŸ­ã™ãã‚‹å˜èªã‚’æ’é™¤
        for w in t_clean.split():
            if len(w) >= 2:
                tokens.append(w)
    counter = Counter(tokens)
    return counter.most_common(top_n)

# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿ï¼ˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ or ã‚µãƒ³ãƒ—ãƒ«ï¼‰
if uploaded_file is not None:
    try:
        df = load_csv(uploaded_file)
    except Exception as e:
        st.error(f"CSVã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        st.stop()
    st.success("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
else:
    st.info("CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦è§£æã§ãã¾ã™ã€‚ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¾ã™ã€‚")
    df = load_csv(sample_csv)

# æ­£è¦åŒ–ï¼ˆã‚«ãƒ©ãƒ åã‚’æœŸå¾…ã™ã‚‹æ—¥æœ¬èªåã«ï¼‰
df = normalize_columns(df)

# å¿…è¦ãªã‚«ãƒ©ãƒ ãŒãªã‘ã‚Œã°è­¦å‘Š
required_cols = [
    "ç•ªå·",
    "å­¦ç”Ÿç•ªå·",
    "ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆå›ç­”",
    "æˆæ¥­ãŒå½¹ç«‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰",
    "æˆæ¥­ãŒé›£ã—ã‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰",
    "å›ç­”æ—¥æ™‚",
]
missing = [c for c in required_cols if c not in df.columns]
if missing:
    st.warning(f"ä»¥ä¸‹ã®æƒ³å®šã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing}ã€‚å¯èƒ½ãªé™ã‚Šå­˜åœ¨ã™ã‚‹ã‚«ãƒ©ãƒ ã§è§£æã—ã¾ã™ã€‚")

# è¡¨ç¤ºç”¨ã«å…ˆé ­ã‚’å‡ºã™
st.header("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
st.dataframe(df.head(50), use_container_width=True)

# å‹å¤‰æ›
if "å›ç­”æ—¥æ™‚" in df.columns:
    try:
        df["å›ç­”æ—¥æ™‚"] = pd.to_datetime(df["å›ç­”æ—¥æ™‚"])
    except Exception:
        # å¤‰æ›å¤±æ•—ã¯ç„¡è¦–
        pass

# æ•°å€¤ã‚«ãƒ©ãƒ ã‚’å®‰å…¨ã«å¤‰æ›
if "æˆæ¥­ãŒå½¹ç«‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰" in df.columns:
    df["æˆæ¥­ãŒå½¹ç«‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰"] = pd.to_numeric(df["æˆæ¥­ãŒå½¹ç«‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰"], errors="coerce")
if "æˆæ¥­ãŒé›£ã—ã‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰" in df.columns:
    df["æˆæ¥­ãŒé›£ã—ã‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰"] = pd.to_numeric(df["æˆæ¥­ãŒé›£ã—ã‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰"], errors="coerce")

# åŸºæœ¬çµ±è¨ˆ
st.header("é›†è¨ˆãƒ»åŸºæœ¬çµ±è¨ˆ")
col1, col2, col3 = st.columns(3)

total_responses = len(df)
col1.metric("å›ç­”æ•°", total_responses)

if "æˆæ¥­ãŒå½¹ç«‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰" in df.columns:
    avg_useful = df["æˆæ¥­ãŒå½¹ç«‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰"].mean(skipna=True)
    col2.metric("æˆæ¥­ãŒå½¹ç«‹ã£ãŸã‹ï¼ˆå¹³å‡ï¼‰", f"{avg_useful:.2f}" if not np.isnan(avg_useful) else "N/A")
else:
    col2.metric("æˆæ¥­ãŒå½¹ç«‹ã£ãŸã‹ï¼ˆå¹³å‡ï¼‰", "N/A")

if "æˆæ¥­ãŒé›£ã—ã‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰" in df.columns:
    avg_difficulty = df["æˆæ¥­ãŒé›£ã—ã‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰"].mean(skipna=True)
    col3.metric("æˆæ¥­ãŒé›£ã—ã‹ã£ãŸã‹ï¼ˆå¹³å‡ï¼‰", f"{avg_difficulty:.2f}" if not np.isnan(avg_difficulty) else "N/A")
else:
    col3.metric("æˆæ¥­ãŒé›£ã—ã‹ã£ãŸã‹ï¼ˆå¹³å‡ï¼‰", "N/A")

# è©•ä¾¡åˆ†å¸ƒã®ãƒãƒ£ãƒ¼ãƒˆ
st.write("")
st.subheader("è©•ä¾¡ã®åˆ†å¸ƒ")

charts = []
if "æˆæ¥­ãŒå½¹ç«‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰" in df.columns:
    useful_df = df.dropna(subset=["æˆæ¥­ãŒå½¹ç«‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰"])
    useful_counts = useful_df["æˆæ¥­ãŒå½¹ç«‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰"].value_counts().reset_index()
    useful_counts.columns = ["è©•ä¾¡", "ä»¶æ•°"]
    useful_counts["è©•ä¾¡"] = useful_counts["è©•ä¾¡"].astype(str)
    chart1 = alt.Chart(useful_counts).mark_bar().encode(
        x=alt.X("è©•ä¾¡:N", title="è©•ä¾¡ï¼ˆå½¹ç«‹ã£ãŸã‹ï¼‰"),
        y=alt.Y("ä»¶æ•°:Q", title="ä»¶æ•°"),
        color=alt.Color("è©•ä¾¡:N")
    )
    st.altair_chart(chart1, use_container_width=True)
else:
    st.info("ã€Œæˆæ¥­ãŒå½¹ç«‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰ã€ã®åˆ—ãŒãªã„ãŸã‚åˆ†å¸ƒã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")

if "æˆæ¥­ãŒé›£ã—ã‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰" in df.columns:
    diff_df = df.dropna(subset=["æˆæ¥­ãŒé›£ã—ã‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰"])
    diff_counts = diff_df["æˆæ¥­ãŒé›£ã—ã‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰"].value_counts().reset_index()
    diff_counts.columns = ["è©•ä¾¡", "ä»¶æ•°"]
    diff_counts["è©•ä¾¡"] = diff_counts["è©•ä¾¡"].astype(str)
    chart2 = alt.Chart(diff_counts).mark_bar().encode(
        x=alt.X("è©•ä¾¡:N", title="è©•ä¾¡ï¼ˆé›£ã—ã‹ã£ãŸã‹ï¼‰"),
        y=alt.Y("ä»¶æ•°:Q", title="ä»¶æ•°"),
        color=alt.Color("è©•ä¾¡:N")
    )
    st.altair_chart(chart2, use_container_width=True)
else:
    st.info("ã€Œæˆæ¥­ãŒé›£ã—ã‹ã£ãŸã‹ï¼ˆï¼•æ®µéšè©•ä¾¡ï¼‰ã€ã®åˆ—ãŒãªã„ãŸã‚åˆ†å¸ƒã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")

# ãƒ†ã‚­ã‚¹ãƒˆè§£æï¼šé »å‡ºèª
st.write("")
st.subheader("ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆè‡ªç”±è¨˜è¿°ã®é »å‡ºèªï¼ˆç°¡æ˜“ï¼‰")
if "ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆå›ç­”" in df.columns:
    top_words = extract_top_words(df["ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆå›ç­”"].astype(str), top_n=20)
    if top_words:
        top_df = pd.DataFrame(top_words, columns=["èª", "å‡ºç¾å›æ•°"])
        st.table(top_df.head(20))
    else:
        st.write("ååˆ†ãªãƒ†ã‚­ã‚¹ãƒˆãŒãªã„ãŸã‚é »å‡ºèªã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
else:
    st.info("ã€Œã‚¢ãƒ³ã‚±ãƒ¼ãƒˆå›ç­”ã€ã®åˆ—ãŒãªã„ãŸã‚è‡ªç”±è¨˜è¿°è§£æãŒã§ãã¾ã›ã‚“ã€‚")

# æ™‚ç³»åˆ—è§£æï¼šæ—¥åˆ¥ã®å›ç­”æ•°
if "å›ç­”æ—¥æ™‚" in df.columns and pd.api.types.is_datetime64_any_dtype(df["å›ç­”æ—¥æ™‚"]):
    st.write("")
    st.subheader("æ—¥åˆ¥ã®å›ç­”æ•°")
    df["å›ç­”æ—¥"] = df["å›ç­”æ—¥æ™‚"].dt.date
    daily = df.groupby("å›ç­”æ—¥").size().reset_index(name="ä»¶æ•°")
    line = alt.Chart(daily).mark_line(point=True).encode(
        x=alt.X("å›ç­”æ—¥:T", title="å›ç­”æ—¥"),
        y=alt.Y("ä»¶æ•°:Q", title="ä»¶æ•°")
    )
    st.altair_chart(line, use_container_width=True)
else:
    st.info("å›ç­”æ—¥æ™‚ã®åˆ—ãŒãªã„ã€ã¾ãŸã¯æ—¥æ™‚å‹ã«å¤‰æ›ã§ããªã„ãŸã‚æ—¥åˆ¥è§£æã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")

st.write("")
st.caption("æ³¨: ã“ã®ãƒ„ãƒ¼ãƒ«ã¯ç°¡æ˜“è§£æã‚’è¡Œã„ã¾ã™ã€‚ã‚ˆã‚Šé«˜åº¦ãªè‡ªç„¶è¨€èªå‡¦ç†ã‚„æ—¥æœ¬èªå½¢æ…‹ç´ è§£æã‚’è¡Œã†å ´åˆã¯ MeCab ç­‰ã‚’å°å…¥ã—ã¦ãã ã•ã„ã€‚")
